{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prerequisites and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoI7cICAeKAY",
    "outputId": "da037767-0e41-4efb-da3e-14f27db5c329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: tokenizer in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: jupyter in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2025.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: notebook in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (7.4.5)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (6.30.1)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter) (4.4.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (1.8.16)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (311)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab->jupyter) (65.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.26.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.1)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250822)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets torch tokenizer tiktoken matplotlib ipywidgets jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tny4je0AeQLl",
    "outputId": "390479e1-5510-4180-8b31-3438d9502a42"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZIMnCMzglaf"
   },
   "source": [
    "### Step 2: Tokenizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7a31a5e397c748cc9f61f2e071e2d9d1",
      "d780907ca5094fb5b48b770aaccc9052",
      "b04b4bf523374b50b4784b8f0205330d",
      "632924c86b054ac58184edbc0a61d2f2",
      "1b59cf1959a443aebc4cac7a12408f40",
      "9d653658ad2b426db4582b56f811c6aa",
      "e585f202ec8e4b3bb288ae89f254d15b",
      "1f168741e8864ad9a5576f3a4ad36481",
      "92fc8390416e41f38673c6666fcce44c",
      "28acae29bf0e41768a2d8b48f7fc3208",
      "ef82bd584ed24f1bbb62e19d13ea705a"
     ]
    },
    "id": "8PUoe7zngj1j",
    "outputId": "bed53599-a167-46bf-ef37-a46e8bacfdf1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def process(example, encoder=None):\n",
    "    ids = encoder.encode_ordinary(example[\"text\"])\n",
    "    return {\"ids\": ids, \"len\": len(ids)}\n",
    "\n",
    "# Only map once\n",
    "tokenizer = ds.map(\n",
    "    process,\n",
    "    fn_kwargs={\"encoder\": encoder},     # <-- always pass encoder\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"tokenizing the splits\",\n",
    "    num_proc=os.cpu_count(),\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"train.bin\"):\n",
    "    for split_name, dset in tokenizer.items():   # loop over train/valid/test splits\n",
    "        arr_len = np.sum(dset[\"len\"])\n",
    "        filename = f\"{split_name}.bin\"\n",
    "\n",
    "        dtype = np.uint16\n",
    "        arr = np.memmap(filename, dtype=dtype, mode=\"w+\", shape=(arr_len,))\n",
    "        total_batches = 1024*2^10\n",
    "\n",
    "        idx = 0\n",
    "        for batch_idx in tqdm(range(total_batches), desc=f\"writing {filename}\"):\n",
    "            # Batch together samples for faster write\n",
    "            batch = (\n",
    "                dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True)\n",
    "                .with_format(\"numpy\")\n",
    "            )\n",
    "            arr_batch = np.concatenate(batch[\"ids\"])\n",
    "\n",
    "            # write into mmap\n",
    "            arr[idx : idx + len(arr_batch)] = arr_batch\n",
    "            idx += len(arr_batch)\n",
    "\n",
    "        arr.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvMEu0_xoq-B"
   },
   "source": [
    "### Step 3: Create Input-Output batches for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFsxe997ocaa"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = np.memmap('train.bin', dtype = np.uint16, mode = 'r')\n",
    "    else:\n",
    "        data = np.memmap('validation.bin', dtype = np.uint16, mode = 'r')\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    if device_type == 'cuda':\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XudTjppqlBe"
   },
   "source": [
    "### Step 4: Define the SLM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJEpsVQOqnFg"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "import os\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3*config.n_embd, bias=config.bias)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1,2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1,2)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1,2)\n",
    "\n",
    "        if self.flash:\n",
    "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
    "        else:\n",
    "            att = (q @ k.transpose(-2, -1))* (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop=nn.Dropout(config.dropout),\n",
    "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                nn.init.normal_(p, mean=0.0, std = 0.02 / math.sqrt(2 * config.n_layer))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature = 1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate tokens given a conditioning sequence.\n",
    "        idx: Tensor of shape (B, T)\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gW_sImkKwCA0"
   },
   "outputs": [],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size = 50257,\n",
    "    block_size = 128,\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384,\n",
    "    dropout=0.1,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLdEZpF4xkUr"
   },
   "source": [
    "### Step 5: Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gw-L9HSt0R60"
   },
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                with ctx:\n",
    "                    logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42BZ49dhyQdr"
   },
   "source": [
    "### Step 6: Define SLM Training Configuration Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aPFfA3k_yPuk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13fbe3966f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training config\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "\n",
    "learning_rate = 1e-4\n",
    "max_iters = 20000\n",
    "warmup_steps = 1000\n",
    "min_lr = 5e-4\n",
    "eval_iters = 500\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "\n",
    "gradient_accumulation_steps = 32\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type = device_type, dtype=ptdtype)\n",
    "\n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC3YXHl50CBF"
   },
   "source": [
    "### Step 7: Define SLM Training Configuration Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "i5688iW80A0i"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, betas=(0.9, 0.95), weight_decay = 0.1, eps=1e-9)\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps)\n",
    "scheduler_delay = CosineAnnealingLR(optimizer, T_max = max_iters - warmup_steps, eta_min = min_lr)\n",
    "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_delay], milestones=[warmup_steps])\n",
    "\n",
    "scaler = torch.amp.GradScaler(enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_ZSQexo1IxE"
   },
   "source": [
    "### Step 8: Pre-Train the SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fevOMaXN1H6c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af514f4ec6f64880b5be6893e81fec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanmay Sapra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: train loss 9.4536, val loss 9.4607\n",
      "The current Learning rate: 0.00007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanmay Sapra\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000: train loss 8.5085, val loss 8.5131\n",
      "The current Learning rate: 0.00010\n",
      "Epoch 1500: train loss 7.5564, val loss 7.5570\n",
      "The current Learning rate: 0.00010\n",
      "Epoch 2000: train loss 6.7001, val loss 6.7026\n",
      "The current Learning rate: 0.00010\n",
      "Epoch 2500: train loss 6.0091, val loss 6.0036\n",
      "The current Learning rate: 0.00011\n",
      "Epoch 3000: train loss 5.4905, val loss 5.4900\n",
      "The current Learning rate: 0.00011\n",
      "Epoch 3500: train loss 5.0677, val loss 5.0672\n",
      "The current Learning rate: 0.00012\n",
      "Epoch 4000: train loss 4.7443, val loss 4.7424\n",
      "The current Learning rate: 0.00012\n",
      "Epoch 4500: train loss 4.5009, val loss 4.5001\n",
      "The current Learning rate: 0.00013\n",
      "Epoch 5000: train loss 4.2897, val loss 4.2945\n",
      "The current Learning rate: 0.00014\n",
      "Epoch 5500: train loss 4.1278, val loss 4.1260\n",
      "The current Learning rate: 0.00015\n",
      "Epoch 6000: train loss 3.9555, val loss 3.9599\n",
      "The current Learning rate: 0.00016\n",
      "Epoch 6500: train loss 3.8199, val loss 3.8344\n",
      "The current Learning rate: 0.00018\n",
      "Epoch 7000: train loss 3.7039, val loss 3.7174\n",
      "The current Learning rate: 0.00019\n",
      "Epoch 7500: train loss 3.5906, val loss 3.5937\n",
      "The current Learning rate: 0.00020\n",
      "Epoch 8000: train loss 3.4924, val loss 3.4989\n",
      "The current Learning rate: 0.00022\n",
      "Epoch 8500: train loss 3.3994, val loss 3.3989\n",
      "The current Learning rate: 0.00024\n",
      "Epoch 9000: train loss 3.3140, val loss 3.3181\n",
      "The current Learning rate: 0.00025\n",
      "Epoch 9500: train loss 3.2495, val loss 3.2509\n",
      "The current Learning rate: 0.00027\n",
      "Epoch 10000: train loss 3.1772, val loss 3.1768\n",
      "The current Learning rate: 0.00028\n",
      "Epoch 10500: train loss 3.1018, val loss 3.1004\n",
      "The current Learning rate: 0.00030\n",
      "Epoch 11000: train loss 3.0523, val loss 3.0536\n",
      "The current Learning rate: 0.00032\n",
      "Epoch 11500: train loss 2.9811, val loss 2.9887\n",
      "The current Learning rate: 0.00033\n",
      "Epoch 12000: train loss 2.9313, val loss 2.9321\n",
      "The current Learning rate: 0.00035\n",
      "Epoch 12500: train loss 2.8860, val loss 2.8949\n",
      "The current Learning rate: 0.00036\n",
      "Epoch 13000: train loss 2.8368, val loss 2.8352\n",
      "The current Learning rate: 0.00038\n",
      "Epoch 13500: train loss 2.7997, val loss 2.7923\n",
      "The current Learning rate: 0.00040\n",
      "Epoch 14000: train loss 2.7457, val loss 2.7507\n",
      "The current Learning rate: 0.00041\n",
      "Epoch 14500: train loss 2.7044, val loss 2.7079\n",
      "The current Learning rate: 0.00042\n",
      "Epoch 15000: train loss 2.6645, val loss 2.6610\n",
      "The current Learning rate: 0.00044\n",
      "Epoch 15500: train loss 2.6391, val loss 2.6332\n",
      "The current Learning rate: 0.00045\n",
      "Epoch 16000: train loss 2.5953, val loss 2.6042\n",
      "The current Learning rate: 0.00046\n",
      "Epoch 16500: train loss 2.5639, val loss 2.5674\n",
      "The current Learning rate: 0.00047\n",
      "Epoch 17000: train loss 2.5200, val loss 2.5289\n",
      "The current Learning rate: 0.00048\n",
      "Epoch 17500: train loss 2.4915, val loss 2.4997\n",
      "The current Learning rate: 0.00048\n",
      "Epoch 18000: train loss 2.4717, val loss 2.4675\n",
      "The current Learning rate: 0.00049\n",
      "Epoch 18500: train loss 2.4502, val loss 2.4509\n",
      "The current Learning rate: 0.00049\n",
      "Epoch 19000: train loss 2.4205, val loss 2.4212\n",
      "The current Learning rate: 0.00050\n",
      "Epoch 19500: train loss 2.3957, val loss 2.4017\n",
      "The current Learning rate: 0.00050\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('Inf')\n",
    "best_model_params_path = './best_model_params.pt'\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(max_iters)):\n",
    "    if epoch % eval_iters == 0 and epoch != 0:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        print(f\"The current Learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "        train_loss_list += [losses['train']]\n",
    "        validation_loss_list += [losses['val']]\n",
    "\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "    X,y = get_batch(\"train\")\n",
    "    X,y = X.to(device), y.to(device)\n",
    "\n",
    "    with ctx:\n",
    "        logits, loss = model(X, y)\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "    if((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiF9wwd87Nhf"
   },
   "source": [
    "### Step 9: Plot the SLM Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eg93z01b5eoY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
    "validate_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
    "\n",
    "plt.plot(train_loss_list_converted, 'g', label = 'train loss')\n",
    "plt.plot(validate_loss_list_converted, 'r', label = 'validation loss')\n",
    "plt.xlabel(\"Steps = Every 100 epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLxC4jMB8CFx"
   },
   "source": [
    "### Step 10: Run SLM Inference on our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R__vvSRM9wQR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2025.9.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanmay sapra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken\n",
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IDVUyovA8BFj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanmay Sapra\\AppData\\Local\\Temp\\ipykernel_1620\\1792525618.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(config)\n",
    "device = 'cuda'\n",
    "best_model_params_path = 'best_model_params.pt'\n",
    "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aUGYJUvd9Lwe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a pumpkin. Everyone was very excited and wanted to go on the lawn. One day, Joe hopped into the garden and smiled with excitement. He had already found a mixer all so red leaves! Sammy tried to grab the steak, but it was too cold.\n",
      "\n",
      "Mark didn't but frowned. They had an idea. They took the sandwich in a bite you and came in the oven. Inside the kitchen, there was wider than terrible things in the plate. Sally was so happy he had eaten up the mixer, but he was not happy. He drank melony and said goodbye to it!\n",
      "\n",
      "When the damage was done, child wasn't happy to br tested her best rule. They started to cry in time Yeah, lets do a hot with the cart. a friendly man had ate the cake until the pizza was nice and happy.\n",
      "\n",
      "Where about she had eaten their tea party of snow, thanked the driver with an honest\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Once upon a time there was a pumpkin.\"\n",
    "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
    "y = model.generate(context, 200)\n",
    "print(enc.decode(y.squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SXqQFL9_9j5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A little girl went to the woods, but Mom said, \"Em! Come inside with me in.\" It was time soon.\n",
      "\n",
      "Emma was very happy. She ate all of the plants, encourage her dad to make sure Lily came down. This time, she tried to copy the frog to get the carrot. Lily was very happy and they all played the sheep happily all day long.Once upon a time, there was a small boy named Timmy. Timmy liked to play with his toys and make them look for snakes. When Timmy's mommy came over, said, \"Timmy, that's important to clean up your toys get home so loving around. I can't have to buy\"Mommy, can we, Mommy?\"Timmy was in the living room. She wanted to wrap up.\n",
      "\n",
      "\"Timmy, Daddy, Lily, can you make me clean so that we can clean your toys!\" he said, \"I feel anxious!\" \n",
      "\n",
      "His mom smiled and said\n"
     ]
    }
   ],
   "source": [
    "sentence = \"A little girl went to the woods\"\n",
    "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
    "y = model.generate(context, 200)\n",
    "print(enc.decode(y.squeeze().tolist()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b59cf1959a443aebc4cac7a12408f40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f168741e8864ad9a5576f3a4ad36481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28acae29bf0e41768a2d8b48f7fc3208": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "632924c86b054ac58184edbc0a61d2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28acae29bf0e41768a2d8b48f7fc3208",
      "placeholder": "",
      "style": "IPY_MODEL_ef82bd584ed24f1bbb62e19d13ea705a",
      "value": "326716/2119719[01:03&lt;04:40,6387.55examples/s]"
     }
    },
    "7a31a5e397c748cc9f61f2e071e2d9d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d780907ca5094fb5b48b770aaccc9052",
       "IPY_MODEL_b04b4bf523374b50b4784b8f0205330d",
       "IPY_MODEL_632924c86b054ac58184edbc0a61d2f2"
      ],
      "layout": "IPY_MODEL_1b59cf1959a443aebc4cac7a12408f40"
     }
    },
    "92fc8390416e41f38673c6666fcce44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d653658ad2b426db4582b56f811c6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b04b4bf523374b50b4784b8f0205330d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f168741e8864ad9a5576f3a4ad36481",
      "max": 2119719,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92fc8390416e41f38673c6666fcce44c",
      "value": 327514
     }
    },
    "d780907ca5094fb5b48b770aaccc9052": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d653658ad2b426db4582b56f811c6aa",
      "placeholder": "",
      "style": "IPY_MODEL_e585f202ec8e4b3bb288ae89f254d15b",
      "value": "tokenizingthesplits(num_proc=2):15%"
     }
    },
    "e585f202ec8e4b3bb288ae89f254d15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef82bd584ed24f1bbb62e19d13ea705a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

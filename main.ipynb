{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prerequisites and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:15:00.235100Z",
     "iopub.status.busy": "2025-10-28T13:15:00.234903Z",
     "iopub.status.idle": "2025-10-28T13:16:17.342651Z",
     "shell.execute_reply": "2025-10-28T13:16:17.341872Z",
     "shell.execute_reply.started": "2025-10-28T13:15:00.235081Z"
    },
    "id": "DoI7cICAeKAY",
    "outputId": "da037767-0e41-4efb-da3e-14f27db5c329",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: tokenizer in /usr/local/lib/python3.11/dist-packages (3.5.3)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.5.4)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.1.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.4.5)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter) (6.17.1)\n",
      "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (from jupyter) (3.6.8)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (1.8.15)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-server~=2.19 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (2.12.5)\n",
      "Requirement already satisfied: jupyter-ydoc~=0.2.4 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (0.2.5)\n",
      "Requirement already satisfied: jupyter-server-ydoc~=0.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbclassic in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (25.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (5.10.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter) (0.22.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter) (0.5.13)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter) (4.4.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (4.11.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: jupyter-server-fileid<1,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (0.9.3)\n",
      "Requirement already satisfied: ypy-websocket<0.9.0,>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (0.8.4)\n",
      "Requirement already satisfied: y-py<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-ydoc~=0.2.4->jupyterlab->jupyter) (0.6.2)\n",
      "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server~=2.19->jupyterlab->jupyter) (4.25.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic->jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->jupyter) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server~=2.19->jupyterlab->jupyter) (0.26.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: aiofiles<23,>=22.1.0 in /usr/local/lib/python3.11/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (22.1.0)\n",
      "Requirement already satisfied: aiosqlite<1,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from ypy-websocket<0.9.0,>=0.8.2->jupyter-server-ydoc~=0.8.0->jupyterlab->jupyter) (0.21.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.23)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (2.9.0.20250822)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets torch torchvision tokenizer tiktoken matplotlib ipywidgets jupyter transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Multiple Financial Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:16:17.343816Z",
     "iopub.status.busy": "2025-10-28T13:16:17.343595Z",
     "iopub.status.idle": "2025-10-28T13:16:33.802025Z",
     "shell.execute_reply": "2025-10-28T13:16:33.801149Z",
     "shell.execute_reply.started": "2025-10-28T13:16:17.343795Z"
    },
    "id": "tny4je0AeQLl",
    "outputId": "390479e1-5510-4180-8b31-3438d9502a42",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINANCIAL SLM - Multi-Dataset Preparation\n",
      "================================================================================\n",
      "\n",
      "[1/3] Loading Finance Alpaca dataset...\n",
      "✓ Finance Alpaca loaded: 68,912 examples\n",
      "  Purpose: Financial instruction-following and Q&A\n",
      "\n",
      "[2/3] Loading Financial PhraseBank dataset...\n",
      "✓ Financial PhraseBank loaded: 3,100 examples\n",
      "  Purpose: Financial sentiment understanding (positive/negative/neutral)\n",
      "  Sentiment distribution: {2: 866, 0: 382, 1: 1852}\n",
      "\n",
      "[3/3] Creating custom investment recommendation dataset...\n",
      "✓ Custom investment dataset created: 5 examples\n",
      "  Purpose: Investment-specific reasoning and recommendations\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINANCIAL SLM - Multi-Dataset Preparation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# DATASET 1: Finance Alpaca (Instruction-following Q&A)\n",
    "print(\"\\n[1/3] Loading Finance Alpaca dataset...\")\n",
    "finance_alpaca = load_dataset(\"gbharti/finance-alpaca\")\n",
    "print(f\"✓ Finance Alpaca loaded: {len(finance_alpaca['train']):,} examples\")\n",
    "print(f\"  Purpose: Financial instruction-following and Q&A\")\n",
    "\n",
    "# DATASET 2: Financial PhraseBank (Sentiment Analysis)\n",
    "print(\"\\n[2/3] Loading Financial PhraseBank dataset...\")\n",
    "financial_phrasebank = load_dataset(\"atrost/financial_phrasebank\")\n",
    "print(f\"✓ Financial PhraseBank loaded: {len(financial_phrasebank['train']):,} examples\")\n",
    "print(f\"  Purpose: Financial sentiment understanding (positive/negative/neutral)\")\n",
    "\n",
    "sentiment_counts = {}\n",
    "for example in financial_phrasebank['train']:\n",
    "    label = example['label']\n",
    "    sentiment_counts[label] = sentiment_counts.get(label, 0) + 1\n",
    "print(f\"  Sentiment distribution: {sentiment_counts}\")\n",
    "\n",
    "# DATASET 3: Custom Investment Dataset\n",
    "print(\"\\n[3/3] Creating custom investment recommendation dataset...\")\n",
    "\n",
    "custom_investment_data = [\n",
    "    {\n",
    "        \"instruction\": \"Should I invest in this company?\",\n",
    "        \"input\": \"Tech company, Revenue growth: 25% YoY, P/E ratio: 45, Debt-to-Equity: 0.3, Market cap: $50B\",\n",
    "        \"output\": \"POSITIVE OUTLOOK - Consider investing. The 25% revenue growth indicates strong market demand. P/E of 45 is elevated but reasonable for high-growth tech. Low debt-to-equity (0.3) shows financial stability. Risk: High P/E means vulnerability to market corrections. Recommendation: Suitable for growth-oriented portfolios with 3-5 year horizon. Disclaimer: Not financial advice.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Analyze this company's financial health\",\n",
    "        \"input\": \"Manufacturing company, Operating margin: 8%, Current ratio: 1.5, ROE: 12%, Industry avg ROE: 10%\",\n",
    "        \"output\": \"MODERATE HEALTH - The company shows decent performance. Operating margin of 8% is acceptable for manufacturing. Current ratio of 1.5 indicates adequate liquidity. ROE of 12% exceeds industry average (10%), suggesting efficient capital use. Consider for value portfolios. Monitor industry trends and competition.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"What are red flags in financial statements?\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"Key red flags to watch: 1) Declining revenue with increasing receivables (fake sales), 2) Operating cash flow < Net income (earnings manipulation), 3) High debt-to-equity ratio >2.0 (financial risk), 4) Frequent auditor changes (governance issues), 5) Unusual related-party transactions, 6) Inventory growing faster than sales (obsolete stock). Always cross-verify with multiple quarters of data.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Explain Price-to-Earnings ratio\",\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"P/E ratio = Stock Price ÷ Earnings Per Share. It shows how much investors pay for each dollar of earnings. Example: P/E of 20 means investors pay $20 for $1 of annual earnings. Low P/E (<15): Potentially undervalued or mature company. High P/E (>25): Growth expectations or overvaluation. Compare within same industry. Tech averages 30+, utilities average 15-20.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"How to diversify investment portfolio?\",\n",
    "        \"input\": \"Age: 30, Risk tolerance: Moderate, Investment horizon: 20 years\",\n",
    "        \"output\": \"Recommended allocation for 30-year-old with moderate risk: 60% stocks (40% domestic large-cap, 15% international, 5% small-cap), 30% bonds (20% government, 10% corporate), 10% alternatives (REITs, commodities). Rebalance annually. Given 20-year horizon, can tolerate more equity risk. Gradually shift to conservative allocation approaching retirement. Dollar-cost average monthly to reduce timing risk.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "from datasets import Dataset\n",
    "custom_dataset = Dataset.from_list(custom_investment_data)\n",
    "print(f\"✓ Custom investment dataset created: {len(custom_dataset)} examples\")\n",
    "print(f\"  Purpose: Investment-specific reasoning and recommendations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Format and Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:16:33.804347Z",
     "iopub.status.busy": "2025-10-28T13:16:33.803920Z",
     "iopub.status.idle": "2025-10-28T13:16:37.497349Z",
     "shell.execute_reply": "2025-10-28T13:16:37.496790Z",
     "shell.execute_reply.started": "2025-10-28T13:16:33.804330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Formatting datasets\n",
      "✓ Finance Alpaca formatted: 68,912 examples\n",
      "✓ Financial PhraseBank formatted: 3,100 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0342d27747d84873b9f6cb2e1d8d963e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting Custom:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Custom dataset formatted: 5 examples\n",
      "\n",
      "✓ Combined dataset size: 72,017 examples\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📝 Formatting datasets\")\n",
    "\n",
    "def format_text(example):\n",
    "    \"\"\"Unified formatting function\"\"\"\n",
    "    text = f\"\"\"### Instruction:\n",
    "{example['instruction']}\n",
    "\n",
    "### Input:\n",
    "{example['input']}\n",
    "\n",
    "### Response:\n",
    "{example['output']}\n",
    "\n",
    "### End\"\"\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "alpaca_formatted = finance_alpaca['train'].map(format_text, desc=\"Formatting Alpaca\")\n",
    "print(f\"✓ Finance Alpaca formatted: {len(alpaca_formatted):,} examples\")\n",
    "\n",
    "datasets_to_combine = [alpaca_formatted]\n",
    "\n",
    "def format_phrasebank(example):\n",
    "    sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    sentiment = sentiment_map[example['label']]\n",
    "    \n",
    "    return {\n",
    "        \"instruction\": \"Analyze the sentiment of this financial statement from an investor perspective.\",\n",
    "        \"input\": example['sentence'],\n",
    "        \"output\": f\"The sentiment of this statement is {sentiment}. This suggests the news may have a {sentiment} influence on stock price from an investor's viewpoint.\"\n",
    "    }\n",
    "\n",
    "phrasebank_with_fields = financial_phrasebank['train'].map(format_phrasebank, desc=\"Converting PhraseBank\")\n",
    "phrasebank_formatted = phrasebank_with_fields.map(format_text, desc=\"Formatting PhraseBank\")\n",
    "print(f\"✓ Financial PhraseBank formatted: {len(phrasebank_formatted):,} examples\")\n",
    "datasets_to_combine.append(phrasebank_formatted)\n",
    "\n",
    "custom_formatted = custom_dataset.map(format_text, desc=\"Formatting Custom\")\n",
    "print(f\"✓ Custom dataset formatted: {len(custom_formatted)} examples\")\n",
    "datasets_to_combine.append(custom_formatted)\n",
    "\n",
    "for i, ds in enumerate(datasets_to_combine):\n",
    "    datasets_to_combine[i] = ds.remove_columns(\n",
    "        [col for col in ds.column_names if col != 'text']\n",
    "    )\n",
    "\n",
    "combined_dataset = concatenate_datasets(datasets_to_combine)\n",
    "\n",
    "print(f\"\\n✓ Combined dataset size: {len(combined_dataset):,} examples\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:16:37.498184Z",
     "iopub.status.busy": "2025-10-28T13:16:37.497978Z",
     "iopub.status.idle": "2025-10-28T13:16:37.528454Z",
     "shell.execute_reply": "2025-10-28T13:16:37.527853Z",
     "shell.execute_reply.started": "2025-10-28T13:16:37.498158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✂️ Creating train/test split...\n",
      "✓ Splits created:\n",
      "  - Train: 57,613 examples\n",
      "  - Test: 14,404 examples\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✂️ Creating train/test split...\")\n",
    "\n",
    "dataset_split = combined_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(f\"✓ Splits created:\")\n",
    "print(f\"  - Train: {len(dataset_split['train']):,} examples\")\n",
    "print(f\"  - Test: {len(dataset_split['test']):,} examples\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZIMnCMzglaf"
   },
   "source": [
    "### Step 5: Tokenize the Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:16:37.529974Z",
     "iopub.status.busy": "2025-10-28T13:16:37.529677Z",
     "iopub.status.idle": "2025-10-28T13:16:51.919006Z",
     "shell.execute_reply": "2025-10-28T13:16:51.918067Z",
     "shell.execute_reply.started": "2025-10-28T13:16:37.529955Z"
    },
    "id": "8PUoe7zngj1j",
    "outputId": "bed53599-a167-46bf-ef37-a46e8bacfdf1",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️ Tokenizing dataset...\n",
      "✓ Tokenizer loaded: gpt2\n",
      "  Vocabulary size: 50,257\n",
      "\n",
      "Tokenizing train and test splits...\n",
      "\n",
      "✓ Tokenization complete!\n",
      "  Columns after tokenization: ['ids', 'len']\n",
      "\n",
      "📋 Sample tokenized example:\n",
      "  First 20 token IDs: [21017, 46486, 25, 198, 37702, 2736, 262, 15598, 286, 428, 3176, 2643, 422, 281, 15811, 6650, 13, 198, 198, 21017]\n",
      "  Token count: 120\n",
      "\n",
      "📊 Token Statistics:\n",
      "  - Train tokens: 7,684,648\n",
      "  - Test tokens: 1,914,507\n",
      "  - Total tokens: 9,599,155\n",
      "  - Avg tokens/example (train): 133.4\n",
      "  - Avg tokens/example (test): 132.9\n",
      "  - Max tokens in example: 3543\n",
      "  - Min tokens in example: 25\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tiktoken\n",
    "\n",
    "print(\"\\n⚙️ Tokenizing dataset...\")\n",
    "\n",
    "# Initialize GPT-2 tokenizer\n",
    "encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "print(f\"✓ Tokenizer loaded: {encoder.name}\")\n",
    "print(f\"  Vocabulary size: {encoder.n_vocab:,}\")\n",
    "\n",
    "def tokenize_example(example, encoder):\n",
    "    \"\"\"\n",
    "    Convert text string to token IDs.\n",
    "    Returns both the token IDs list and length for statistics.\n",
    "    \"\"\"\n",
    "    ids = encoder.encode_ordinary(example[\"text\"])\n",
    "    return {\"ids\": ids, \"len\": len(ids)}\n",
    "\n",
    "print(\"\\nTokenizing train and test splits...\")\n",
    "tokenized = dataset_split.map(\n",
    "    tokenize_example,\n",
    "    fn_kwargs={\"encoder\": encoder},\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing\",\n",
    "    num_proc=os.cpu_count(),\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Tokenization complete!\")\n",
    "print(f\"  Columns after tokenization: {tokenized['train'].column_names}\")\n",
    "\n",
    "print(f\"\\n📋 Sample tokenized example:\")\n",
    "print(f\"  First 20 token IDs: {tokenized['train'][0]['ids'][:20]}\")\n",
    "print(f\"  Token count: {tokenized['train'][0]['len']}\")\n",
    "\n",
    "train_tokens = np.sum(tokenized['train']['len'], dtype=np.int64)\n",
    "test_tokens = np.sum(tokenized['test']['len'], dtype=np.int64)\n",
    "total_tokens = train_tokens + test_tokens\n",
    "\n",
    "print(f\"\\n📊 Token Statistics:\")\n",
    "print(f\"  - Train tokens: {train_tokens:,}\")\n",
    "print(f\"  - Test tokens: {test_tokens:,}\")\n",
    "print(f\"  - Total tokens: {total_tokens:,}\")\n",
    "print(f\"  - Avg tokens/example (train): {train_tokens / len(tokenized['train']):.1f}\")\n",
    "print(f\"  - Avg tokens/example (test): {test_tokens / len(tokenized['test']):.1f}\")\n",
    "print(f\"  - Max tokens in example: {max(tokenized['train']['len'])}\")\n",
    "print(f\"  - Min tokens in example: {min(tokenized['train']['len'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvMEu0_xoq-B"
   },
   "source": [
    "### Step 6: Load Tokenized Data Directly to RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:16:51.920421Z",
     "iopub.status.busy": "2025-10-28T13:16:51.920126Z",
     "iopub.status.idle": "2025-10-28T13:17:02.906431Z",
     "shell.execute_reply": "2025-10-28T13:17:02.905654Z",
     "shell.execute_reply.started": "2025-10-28T13:16:51.920387Z"
    },
    "id": "gFsxe997ocaa",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Loading tokenized data to RAM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b7ed5ad5a04ae4a2025dbd7cc0cdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading train:   0%|          | 0/57613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Train data: 7,684,648 tokens (58.63 MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff368e2ed184a0b80abce12923f1191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading test:   0%|          | 0/14404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test data: 1,914,507 tokens (14.61 MB)\n",
      "✓ Data ready for training\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"\\n💾 Loading tokenized data to RAM\")\n",
    "\n",
    "train_data = torch.cat([\n",
    "    torch.tensor(example['ids'], dtype=torch.long) \n",
    "    for example in tqdm(tokenized['train'], desc=\"Loading train\")\n",
    "])\n",
    "print(f\"✓ Train data: {len(train_data):,} tokens ({len(train_data)*8/1024/1024:.2f} MB)\")\n",
    "\n",
    "test_data = torch.cat([\n",
    "    torch.tensor(example['ids'], dtype=torch.long) \n",
    "    for example in tqdm(tokenized['test'], desc=\"Loading test\")\n",
    "])\n",
    "print(f\"✓ Test data: {len(test_data):,} tokens ({len(test_data)*8/1024/1024:.2f} MB)\")\n",
    "\n",
    "def get_batch(split, batch_size, block_size, device, device_type):\n",
    "    \"\"\"Fast in-memory batch generation - no disk I/O\"\"\"\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    \n",
    "    if device_type == 'cuda':\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "print(\"✓ Data ready for training\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XudTjppqlBe"
   },
   "source": [
    "### Step 7: Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:17:02.907590Z",
     "iopub.status.busy": "2025-10-28T13:17:02.907362Z",
     "iopub.status.idle": "2025-10-28T13:17:04.112212Z",
     "shell.execute_reply": "2025-10-28T13:17:04.111390Z",
     "shell.execute_reply.started": "2025-10-28T13:17:02.907564Z"
    },
    "id": "HJEpsVQOqnFg",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 21:17:56.629944: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761686276.647435     327 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761686276.652432     327 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING PRETRAINED GPT-2\n",
      "================================================================================\n",
      "✓ Pretrained GPT-2 loaded (124M parameters)\n",
      "\n",
      "✓ Model ready for fine-tuning\n",
      "  Parameters: 124.44M\n",
      "  Pretrained on: ~40GB of web text\n",
      "  Now fine-tuning on: Financial data\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"LayerNorm with optional bias\"\"\"\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"Multi-head causal self-attention\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        \n",
    "        # Q, K, V projections for all heads in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # Output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # Regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        \n",
    "        # Flash attention support (much faster)\n",
    "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            # Causal mask for non-flash attention\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()  # batch, sequence length, embedding dim\n",
    "        \n",
    "        # Calculate Q, K, V for all heads in batch\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "\n",
    "        # Efficient attention\n",
    "        if self.flash:\n",
    "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, \n",
    "                                                dropout_p=self.attn_dropout.p if self.training else 0.0, \n",
    "                                                is_causal=True)\n",
    "        else:\n",
    "            # Manual attention computation\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Feed-forward network\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer block: attention + MLP with residual connections\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    \"\"\"GPT model configuration\"\"\"\n",
    "    block_size: int       # Max sequence length\n",
    "    vocab_size: int       # Vocabulary size\n",
    "    n_layer: int          # Number of transformer blocks\n",
    "    n_head: int           # Number of attention heads\n",
    "    n_embd: int           # Embedding dimension\n",
    "    dropout: float = 0.0  # Dropout rate\n",
    "    bias: bool = True     # Use bias in linear layers\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    \"\"\"GPT Language Model\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte=nn.Embedding(config.vocab_size, config.n_embd),  # Token embeddings\n",
    "            wpe=nn.Embedding(config.block_size, config.n_embd),  # Position embeddings\n",
    "            drop=nn.Dropout(config.dropout),\n",
    "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        \n",
    "        # Weight tying: share embeddings with output layer\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        \n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "        \n",
    "        # Forward pass\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        \n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # Training mode: compute loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            # Inference mode: only compute last token\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate new tokens autoregressively.\n",
    "        \n",
    "        Args:\n",
    "            idx: Input token indices [B, T]\n",
    "            max_new_tokens: Number of tokens to generate\n",
    "            temperature: Sampling temperature (higher = more random)\n",
    "            top_k: If set, only sample from top k most likely tokens\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop context if needed\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # Get predictions\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # Optional top-k filtering\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            \n",
    "            # Sample from distribution\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model configuration for Financial SLM\n",
    "config = GPTConfig(\n",
    "    vocab_size=50257,\n",
    "    block_size=1024,\n",
    "    n_layer=8,\n",
    "    n_head=12,\n",
    "    n_embd=768,\n",
    "    dropout=0.2,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "model = GPT(config)\n",
    "\n",
    "# Load pretrained GPT-2 weights from Hugging Face\n",
    "print(\"\\nLoading pretrained GPT-2 weights into custom model...\")\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "pretrained_hf = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "pretrained_dict = pretrained_hf.state_dict()\n",
    "\n",
    "# Map Hugging Face weights to your custom model\n",
    "model_dict = model.state_dict()\n",
    "mapped_dict = {}\n",
    "\n",
    "# Weight mapping (Hugging Face → Your model)\n",
    "weight_map = {\n",
    "    # Token embeddings\n",
    "    'transformer.wte.weight': 'transformer.wte.weight',\n",
    "    # Position embeddings\n",
    "    'transformer.wpe.weight': 'transformer.wpe.weight',\n",
    "    # Final layer norm\n",
    "    'transformer.ln_f.weight': 'transformer.ln_f.weight',\n",
    "    'transformer.ln_f.bias': 'transformer.ln_f.bias',\n",
    "    # Language model head\n",
    "    'lm_head.weight': 'lm_head.weight',\n",
    "}\n",
    "\n",
    "# Copy embeddings and layer norm\n",
    "for hf_key, custom_key in weight_map.items():\n",
    "    if hf_key in pretrained_dict and custom_key in model_dict:\n",
    "        mapped_dict[custom_key] = pretrained_dict[hf_key]\n",
    "        print(f\"  ✓ Loaded {custom_key}\")\n",
    "\n",
    "# Copy transformer blocks\n",
    "for layer_idx in range(8):\n",
    "    # Attention weights\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.attn.c_attn.weight'] = pretrained_dict[f'transformer.h.{layer_idx}.attn.c_attn.weight']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.attn.c_attn.bias'] = pretrained_dict[f'transformer.h.{layer_idx}.attn.c_attn.bias']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.attn.c_proj.weight'] = pretrained_dict[f'transformer.h.{layer_idx}.attn.c_proj.weight']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.attn.c_proj.bias'] = pretrained_dict[f'transformer.h.{layer_idx}.attn.c_proj.bias']\n",
    "    \n",
    "    # MLP weights\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.mlp.c_fc.weight'] = pretrained_dict[f'transformer.h.{layer_idx}.mlp.c_fc.weight']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.mlp.c_fc.bias'] = pretrained_dict[f'transformer.h.{layer_idx}.mlp.c_fc.bias']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.mlp.c_proj.weight'] = pretrained_dict[f'transformer.h.{layer_idx}.mlp.c_proj.weight']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.mlp.c_proj.bias'] = pretrained_dict[f'transformer.h.{layer_idx}.mlp.c_proj.bias']\n",
    "    \n",
    "    # Layer norms\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.ln1.weight'] = pretrained_dict[f'transformer.h.{layer_idx}.ln_1.weight']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.ln1.bias'] = pretrained_dict[f'transformer.h.{layer_idx}.ln_1.bias']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.ln2.weight'] = pretrained_dict[f'transformer.h.{layer_idx}.ln_2.weight']\n",
    "    mapped_dict[f'transformer.h.{layer_idx}.ln2.bias'] = pretrained_dict[f'transformer.h.{layer_idx}.ln_2.bias']\n",
    "\n",
    "# Load the mapped weights\n",
    "model.load_state_dict(mapped_dict, strict=False)\n",
    "print(f\"\\n✓ Pretrained GPT-2 weights loaded into custom model!\")\n",
    "print(f\"  English understanding: ✓ Inherited from GPT-2\")\n",
    "print(f\"  Model architecture: Custom GPT implementation\")\n",
    "print(f\"  Ready for: Fine-tuning on financial data\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"\\n✓ Model ready for fine-tuning\")\n",
    "print(f\"  Parameters: {n_params/1e6:.2f}M\")\n",
    "print(f\"  Context window: {config.block_size} tokens\")\n",
    "print(f\"  Embedding dimension: {config.n_embd}\")\n",
    "print(f\"  Transformer blocks: {config.n_layer}\")\n",
    "print(f\"  Attention heads: {config.n_head}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42BZ49dhyQdr"
   },
   "source": [
    "### Step 8: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:17:04.114852Z",
     "iopub.status.busy": "2025-10-28T13:17:04.114592Z",
     "iopub.status.idle": "2025-10-28T13:17:04.322002Z",
     "shell.execute_reply": "2025-10-28T13:17:04.321243Z",
     "shell.execute_reply.started": "2025-10-28T13:17:04.114834Z"
    },
    "id": "aPFfA3k_yPuk",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINANCIAL SLM - Training Configuration\n",
      "================================================================================\n",
      "✓ Training configuration set:\n",
      "  Device: cuda (cuda)\n",
      "  Mixed precision: bfloat16\n",
      "  Learning rate: 5e-05\n",
      "  Max iterations: 1,000\n",
      "  Batch size: 16 (effective: 128)\n",
      "  Block size: 256\n",
      "  Eval interval: 100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from contextlib import nullcontext\n",
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINANCIAL SLM - Training Configuration\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Training hyperparameters\n",
    "learning_rate = 5e-5\n",
    "max_iters = 1000\n",
    "warmup_steps = 100\n",
    "min_lr = 1e-6\n",
    "eval_interval = 100\n",
    "batch_size = 8\n",
    "block_size = 1024\n",
    "gradient_accumulation_steps = 16\n",
    "\n",
    "# Mixed precision setup\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(f\"✓ Training configuration set:\")\n",
    "print(f\"  Device: {device} ({device_type})\")\n",
    "print(f\"  Mixed precision: {dtype}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Max iterations: {max_iters:,}\")\n",
    "print(f\"  Batch size: {batch_size} (effective: {batch_size * gradient_accumulation_steps})\")\n",
    "print(f\"  Block size: {block_size}\")\n",
    "print(f\"  Eval interval: {eval_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Loss Estimation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:17:04.322997Z",
     "iopub.status.busy": "2025-10-28T13:17:04.322793Z",
     "iopub.status.idle": "2025-10-28T13:17:04.328764Z",
     "shell.execute_reply": "2025-10-28T13:17:04.327969Z",
     "shell.execute_reply.started": "2025-10-28T13:17:04.322981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters=200):\n",
    "    \"\"\"\n",
    "    Estimate model loss on train and test sets.\n",
    "    \n",
    "    Args:\n",
    "        model: The GPT model\n",
    "        eval_iters: Number of batches to evaluate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'train' and 'val' losses\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    \n",
    "    for split in ['train', 'val']:  # 'val' uses test.bin\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        \n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size, block_size, device, device_type)\n",
    "            \n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        \n",
    "        out[split] = losses.mean()\n",
    "    \n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "print(\"✓ Loss estimation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC3YXHl50CBF"
   },
   "source": [
    "### Step 10: Optimizer and Scheduler Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:17:04.329705Z",
     "iopub.status.busy": "2025-10-28T13:17:04.329454Z",
     "iopub.status.idle": "2025-10-28T13:17:08.795037Z",
     "shell.execute_reply": "2025-10-28T13:17:08.794214Z",
     "shell.execute_reply.started": "2025-10-28T13:17:04.329686Z"
    },
    "id": "i5688iW80A0i",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model moved to cuda\n",
      "✓ Optimizer and scheduler configured\n",
      "  Optimizer: AdamW (lr=5e-05, wd=0.1)\n",
      "  Scheduler: Warmup (100) + Cosine annealing\n",
      "  Mixed precision: bfloat16\n"
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(f\"✓ Model moved to {device}\")\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate, \n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.1,      # L2 regularization\n",
    "    eps=1e-9\n",
    ")\n",
    "\n",
    "# Learning rate scheduler: warmup + cosine annealing\n",
    "scheduler_warmup = LinearLR(optimizer, start_factor=0.1, total_iters=warmup_steps)\n",
    "scheduler_main = CosineAnnealingLR(optimizer, T_max=max_iters-warmup_steps, eta_min=min_lr)\n",
    "scheduler = SequentialLR(optimizer, \n",
    "                        schedulers=[scheduler_warmup, scheduler_main], \n",
    "                        milestones=[warmup_steps])\n",
    "\n",
    "# Gradient scaler for mixed precision\n",
    "scaler = torch.amp.GradScaler(enabled=(dtype == 'float16'))\n",
    "\n",
    "print(\"✓ Optimizer and scheduler configured\")\n",
    "print(f\"  Optimizer: AdamW (lr={learning_rate}, wd=0.1)\")\n",
    "print(f\"  Scheduler: Warmup ({warmup_steps}) + Cosine annealing\")\n",
    "print(f\"  Mixed precision: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_ZSQexo1IxE"
   },
   "source": [
    "### Step 11: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T13:17:08.796598Z",
     "iopub.status.busy": "2025-10-28T13:17:08.795957Z"
    },
    "id": "fevOMaXN1H6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING FINANCIAL SLM FINE-TUNING\n",
      "================================================================================\n",
      "\n",
      "📊 Initial evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial losses - Train: 9.4432, Val: 9.4542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e74457b49a4bf8b5037c7a60434aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fine-tuning Financial SLM:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Step 100\n",
      "   Train loss: 7.2487\n",
      "   Val loss: 7.2468\n",
      "   Learning rate: 0.000010\n",
      "   💾 New best model saved! (val_loss: 7.2468)\n",
      "\n",
      "📈 Step 200\n",
      "   Train loss: 6.1387\n",
      "   Val loss: 6.1466\n",
      "   Learning rate: 0.000016\n",
      "   💾 New best model saved! (val_loss: 6.1466)\n",
      "\n",
      "📈 Step 300\n",
      "   Train loss: 5.8434\n",
      "   Val loss: 5.8453\n",
      "   Learning rate: 0.000022\n",
      "   💾 New best model saved! (val_loss: 5.8453)\n",
      "\n",
      "📈 Step 400\n",
      "   Train loss: 5.4114\n",
      "   Val loss: 5.4338\n",
      "   Learning rate: 0.000027\n",
      "   💾 New best model saved! (val_loss: 5.4338)\n",
      "\n",
      "📈 Step 500\n",
      "   Train loss: 5.1093\n",
      "   Val loss: 5.1152\n",
      "   Learning rate: 0.000033\n",
      "   💾 New best model saved! (val_loss: 5.1152)\n",
      "\n",
      "📈 Step 600\n",
      "   Train loss: 4.9102\n",
      "   Val loss: 4.9496\n",
      "   Learning rate: 0.000039\n",
      "   💾 New best model saved! (val_loss: 4.9496)\n",
      "\n",
      "📈 Step 700\n",
      "   Train loss: 4.8029\n",
      "   Val loss: 4.7828\n",
      "   Learning rate: 0.000044\n",
      "   💾 New best model saved! (val_loss: 4.7828)\n",
      "\n",
      "📈 Step 800\n",
      "   Train loss: 4.6570\n",
      "   Val loss: 4.6740\n",
      "   Learning rate: 0.000050\n",
      "   💾 New best model saved! (val_loss: 4.6740)\n",
      "\n",
      "📈 Step 900\n",
      "   Train loss: 4.5892\n",
      "   Val loss: 4.6038\n",
      "   Learning rate: 0.000050\n",
      "   💾 New best model saved! (val_loss: 4.6038)\n",
      "\n",
      "================================================================================\n",
      "FINE-TUNING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "📊 Final Results:\n",
      "   Best validation loss: 4.6038\n",
      "   Final train loss: 4.5049\n",
      "   Final val loss: 4.5342\n",
      "   Model saved to: ./best_financial_slm.pt\n",
      "\n",
      "🎯 Training Stats:\n",
      "   Total iterations: 1,000\n",
      "   Total examples seen: 128,000\n",
      "   Effective batch size: 128\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING FINANCIAL SLM TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Training tracking\n",
    "best_val_loss = float('inf')\n",
    "best_model_path = './best_financial_slm.pt'\n",
    "train_losses, val_losses = [], []\n",
    "steps_list = []\n",
    "\n",
    "# Initial evaluation\n",
    "print(\"\\n📊 Initial evaluation...\")\n",
    "losses = estimate_loss(model, eval_iters=100)\n",
    "print(f\"Initial losses - Train: {losses['train']:.4f}, Val: {losses['val']:.4f}\")\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for iter_num in tqdm(range(max_iters), desc=\"Training Financial SLM\"):\n",
    "    \n",
    "    # Evaluation\n",
    "    if iter_num % eval_interval == 0 and iter_num > 0:\n",
    "        losses = estimate_loss(model, eval_iters=200)\n",
    "        \n",
    "        print(f\"\\n📈 Step {iter_num:,}\")\n",
    "        print(f\"   Train loss: {losses['train']:.4f}\")\n",
    "        print(f\"   Val loss: {losses['val']:.4f}\")\n",
    "        print(f\"   Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Track losses\n",
    "        train_losses.append(losses['train'])\n",
    "        val_losses.append(losses['val'])\n",
    "        steps_list.append(iter_num)\n",
    "        \n",
    "        # Save best model\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'config': config,\n",
    "                'iter_num': iter_num,\n",
    "                'val_loss': best_val_loss,\n",
    "                'train_loss': losses['train'],\n",
    "            }\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"   💾 New best model saved! (val_loss: {best_val_loss:.4f})\")\n",
    "    \n",
    "    # Training step\n",
    "    X, y = get_batch('train', batch_size, block_size, device, device_type)\n",
    "    \n",
    "    # Forward pass with mixed precision\n",
    "    with ctx:\n",
    "        logits, loss = model(X, y)\n",
    "        loss = loss / gradient_accumulation_steps  # Scale loss for accumulation\n",
    "    \n",
    "    # Backward pass\n",
    "    scaler.scale(loss).backward()\n",
    "    \n",
    "    # Optimizer step (with gradient accumulation)\n",
    "    if ((iter_num + 1) % gradient_accumulation_steps == 0) or (iter_num + 1 == max_iters):\n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Optimizer and scheduler step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "final_losses = estimate_loss(model, eval_iters=5)\n",
    "print(f\"\\n📊 Final Results:\")\n",
    "print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Final train loss: {final_losses['train']:.4f}\")\n",
    "print(f\"   Final val loss: {final_losses['val']:.4f}\")\n",
    "print(f\"   Model saved to: {best_model_path}\")\n",
    "\n",
    "print(f\"\\n🎯 Training Stats:\")\n",
    "print(f\"   Total iterations: {max_iters:,}\")\n",
    "print(f\"   Total examples seen: {max_iters * batch_size * gradient_accumulation_steps:,}\")\n",
    "print(f\"   Effective batch size: {batch_size * gradient_accumulation_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiF9wwd87Nhf"
   },
   "source": [
    "### Step 12: Plot Training Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-28T16:13:14.263Z"
    },
    "id": "eg93z01b5eoY",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VISUALIZING TRAINING RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training curve saved as 'training_loss.png'\n",
      "\n",
      "📊 Loss Statistics:\n",
      "   Initial train loss: 7.2487\n",
      "   Initial val loss: 7.2468\n",
      "   Final train loss: 4.5892\n",
      "   Final val loss: 4.6038\n",
      "   Best val loss: 4.6038\n",
      "   Total improvement: 2.6430 (36.5%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VISUALIZING TRAINING RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert losses to CPU for plotting\n",
    "train_losses_cpu = [loss.cpu() if torch.is_tensor(loss) else loss for loss in train_losses]\n",
    "val_losses_cpu = [loss.cpu() if torch.is_tensor(loss) else loss for loss in val_losses]\n",
    "\n",
    "# Create loss plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(steps_list, train_losses_cpu, 'g-', label='Train Loss', linewidth=2)\n",
    "plt.plot(steps_list, val_losses_cpu, 'r-', label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Training Steps', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Financial SLM Training Progress', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Training curve saved as 'training_loss.png'\")\n",
    "\n",
    "# Print loss statistics\n",
    "print(f\"\\n📊 Loss Statistics:\")\n",
    "print(f\"   Initial train loss: {train_losses_cpu[0]:.4f}\")\n",
    "print(f\"   Initial val loss: {val_losses_cpu[0]:.4f}\")\n",
    "print(f\"   Final train loss: {train_losses_cpu[-1]:.4f}\")\n",
    "print(f\"   Final val loss: {val_losses_cpu[-1]:.4f}\")\n",
    "print(f\"   Best val loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Total improvement: {val_losses_cpu[0] - best_val_loss:.4f} ({(val_losses_cpu[0] - best_val_loss)/val_losses_cpu[0]*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Card & Save Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING MODEL DOCUMENTATION\n",
      "================================================================================\n",
      "✓ Model card saved: MODEL_CARD.md\n",
      "\n",
      "================================================================================\n",
      "📊 TRAINING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "🔧 Model Configuration:\n",
      "  Total parameters: 124,439,808 (124.44M)\n",
      "  Layers: 12\n",
      "  Attention heads: 12\n",
      "  Embedding dimension: 768\n",
      "  Block size: 256\n",
      "  Vocabulary size: 50,257\n",
      "\n",
      "📚 Training Data:\n",
      "  Total training examples: 57,613\n",
      "  Total test examples: 14,404\n",
      "  Total tokens: 9,599,155\n",
      "  Avg tokens per example: 133.3\n",
      "\n",
      "⚙️ Training Configuration:\n",
      "  Learning rate: 5e-05\n",
      "  Training iterations: 1,000\n",
      "  Batch size: 16\n",
      "  Gradient accumulation: 8\n",
      "  Effective batch size: 128\n",
      "  Warmup steps: 100\n",
      "  Eval interval: 100\n",
      "  Mixed precision: bfloat16\n",
      "\n",
      "📈 Training Performance:\n",
      "  Evaluations performed: 9\n",
      "  Best validation loss: 4.6038\n",
      "  Initial train loss: 7.2487\n",
      "  Final train loss: 4.5892\n",
      "  Initial val loss: 7.2468\n",
      "  Final val loss: 4.6038\n",
      "  Total improvement: 2.6430 (36.5%)\n",
      "\n",
      "💾 Files Created:\n",
      "  ✓ best_financial_slm.pt - Model checkpoint\n",
      "  ✓ training_loss.png - Loss curve visualization\n",
      "  ✓ MODEL_CARD.md - Model documentation\n",
      "\n",
      "================================================================================\n",
      "🎉 ALL STEPS COMPLETE - YOUR FINANCIAL SLM IS READY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING MODEL DOCUMENTATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create model card\n",
    "model_card = f\"\"\"\n",
    "# Financial SLM - Model Card\n",
    "\n",
    "## Model Details\n",
    "- **Model Name**: Financial Small Language Model (SLM)\n",
    "- **Model Type**: GPT-2 Fine-tuned Transformer\n",
    "- **Parameters**: {n_params/1e6:.2f}M\n",
    "- **Architecture**: {model.config.n_layer} layers, {model.config.n_head} attention heads, {model.config.n_embd} embedding dim\n",
    "- **Vocabulary**: GPT-2 (50,257 tokens)\n",
    "- **Training Date**: October 29, 2025\n",
    "\n",
    "## Training Data\n",
    "- **Finance Alpaca**: {len(finance_alpaca['train']):,} financial Q&A examples\n",
    "- **Financial PhraseBank**: {len(financial_phrasebank['train']):,} sentiment analysis examples\n",
    "- **Custom Investment Data**: {len(custom_dataset)} curated investment examples\n",
    "- **Total Training Examples**: {len(dataset_split['train']):,}\n",
    "- **Total Tokens**: {total_tokens:,}\n",
    "\n",
    "## Training Configuration\n",
    "- **Optimizer**: AdamW (lr={learning_rate}, weight_decay=0.1)\n",
    "- **Batch Size**: {batch_size} (effective: {batch_size * gradient_accumulation_steps})\n",
    "- **Training Steps**: {max_iters:,}\n",
    "- **Learning Rate Schedule**: Linear warmup ({warmup_steps} steps) + Cosine annealing\n",
    "- **Mixed Precision**: {dtype}\n",
    "- **Hardware**: {'GPU' if device_type == 'cuda' else 'CPU'}\n",
    "\n",
    "## Performance\n",
    "- **Best Validation Loss**: {best_val_loss:.4f}\n",
    "- **Evaluations Performed**: {len(train_losses)}\n",
    "\n",
    "## Capabilities\n",
    "- Financial question answering\n",
    "- Investment analysis and recommendations\n",
    "- Sentiment analysis of financial statements\n",
    "- Company financial health assessment\n",
    "- Portfolio diversification advice\n",
    "- Financial concept explanations\n",
    "\n",
    "## Limitations\n",
    "- Educational purposes only - not financial advice\n",
    "- May generate incorrect or outdated information\n",
    "- Should not be sole basis for investment decisions\n",
    "- Requires human verification and professional advice\n",
    "\n",
    "## Intended Use\n",
    "- Financial education and learning\n",
    "- Investment research assistance\n",
    "- Financial literacy improvement\n",
    "- Prototype for financial chatbots\n",
    "\n",
    "## Ethical Considerations\n",
    "- Always include disclaimers about not being financial advice\n",
    "- Users should consult licensed financial advisors\n",
    "- Model outputs should be fact-checked\n",
    "- Not suitable for automated trading systems\n",
    "\n",
    "## Citation\n",
    "If you use this model, please cite:\n",
    "    Financial SLM (2025)\n",
    "    {n_params/1e6:.1f}M parameter GPT-2 fine-tuned model for financial analysis\n",
    "    Trained on Finance Alpaca + Financial PhraseBank + Custom data\n",
    "\"\"\"\n",
    "\n",
    "# Save model card to file\n",
    "with open('model_card.md', 'w') as f:\n",
    "    f.write(model_card)\n",
    "\n",
    "print(\"✓ Model card saved: model_card.md\")\n",
    "\n",
    "# Print training summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 TRAINING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n🔧 Model Configuration:\")\n",
    "print(f\"  Total parameters: {n_params:,} ({n_params/1e6:.2f}M)\")\n",
    "print(f\"  Layers: {model.config.n_layer}\")\n",
    "print(f\"  Attention heads: {model.config.n_head}\")\n",
    "print(f\"  Embedding dimension: {model.config.n_embd}\")\n",
    "print(f\"  Block size: {block_size}\")\n",
    "print(f\"  Vocabulary size: {model.config.vocab_size:,}\")\n",
    "\n",
    "print(f\"\\n📚 Training Data:\")\n",
    "print(f\"  Total training examples: {len(dataset_split['train']):,}\")\n",
    "print(f\"  Total test examples: {len(dataset_split['test']):,}\")\n",
    "print(f\"  Total tokens: {total_tokens:,}\")\n",
    "print(f\"  Avg tokens per example: {total_tokens / len(combined_dataset):.1f}\")\n",
    "\n",
    "print(f\"\\n⚙️ Training Configuration:\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Training iterations: {max_iters:,}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Gradient accumulation: {gradient_accumulation_steps}\")\n",
    "print(f\"  Effective batch size: {batch_size * gradient_accumulation_steps}\")\n",
    "print(f\"  Warmup steps: {warmup_steps}\")\n",
    "print(f\"  Eval interval: {eval_interval}\")\n",
    "print(f\"  Mixed precision: {dtype}\")\n",
    "\n",
    "print(f\"\\n📈 Training Performance:\")\n",
    "print(f\"  Evaluations performed: {len(train_losses)}\")\n",
    "print(f\"  Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "if len(train_losses) > 0:\n",
    "    initial_train = train_losses[0].item() if torch.is_tensor(train_losses[0]) else train_losses[0]\n",
    "    final_train = train_losses[-1].item() if torch.is_tensor(train_losses[-1]) else train_losses[-1]\n",
    "    initial_val = val_losses[0].item() if torch.is_tensor(val_losses[0]) else val_losses[0]\n",
    "    final_val = val_losses[-1].item() if torch.is_tensor(val_losses[-1]) else val_losses[-1]\n",
    "    \n",
    "    print(f\"  Initial train loss: {initial_train:.4f}\")\n",
    "    print(f\"  Final train loss: {final_train:.4f}\")\n",
    "    print(f\"  Initial val loss: {initial_val:.4f}\")\n",
    "    print(f\"  Final val loss: {final_val:.4f}\")\n",
    "    \n",
    "    improvement = initial_val - best_val_loss\n",
    "    improvement_pct = (improvement / initial_val * 100) if initial_val > 0 else 0\n",
    "    print(f\"  Total improvement: {improvement:.4f} ({improvement_pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n💾 Files Created:\")\n",
    "print(f\"  ✓ best_financial_slm.pt - Model checkpoint\")\n",
    "print(f\"  ✓ training_loss.png - Loss curve visualization\")\n",
    "print(f\"  ✓ MODEL_CARD.md - Model documentation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎉 ALL STEPS COMPLETE - YOUR FINANCIAL SLM IS READY!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b59cf1959a443aebc4cac7a12408f40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f168741e8864ad9a5576f3a4ad36481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28acae29bf0e41768a2d8b48f7fc3208": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "632924c86b054ac58184edbc0a61d2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28acae29bf0e41768a2d8b48f7fc3208",
      "placeholder": "​",
      "style": "IPY_MODEL_ef82bd584ed24f1bbb62e19d13ea705a",
      "value": " 326716/2119719 [01:03&lt;04:40, 6387.55 examples/s]"
     }
    },
    "7a31a5e397c748cc9f61f2e071e2d9d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d780907ca5094fb5b48b770aaccc9052",
       "IPY_MODEL_b04b4bf523374b50b4784b8f0205330d",
       "IPY_MODEL_632924c86b054ac58184edbc0a61d2f2"
      ],
      "layout": "IPY_MODEL_1b59cf1959a443aebc4cac7a12408f40"
     }
    },
    "92fc8390416e41f38673c6666fcce44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d653658ad2b426db4582b56f811c6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b04b4bf523374b50b4784b8f0205330d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f168741e8864ad9a5576f3a4ad36481",
      "max": 2119719,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92fc8390416e41f38673c6666fcce44c",
      "value": 327514
     }
    },
    "d780907ca5094fb5b48b770aaccc9052": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d653658ad2b426db4582b56f811c6aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e585f202ec8e4b3bb288ae89f254d15b",
      "value": "tokenizing the splits (num_proc=2):  15%"
     }
    },
    "e585f202ec8e4b3bb288ae89f254d15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef82bd584ed24f1bbb62e19d13ea705a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
